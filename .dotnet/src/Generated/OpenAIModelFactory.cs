// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;
using System.Linq;
using OpenAI.Assistants;
using OpenAI.Audio;
using OpenAI.Embeddings;
using OpenAI.Images;
using OpenAI.Internal.Models;
using OpenAI.Moderations;
using OpenAI.VectorStores;

namespace OpenAI
{
    /// <summary> Model factory for models. </summary>
    internal static partial class OpenAIModelFactory
    {
        /// <summary> Initializes a new instance of <see cref="Audio.TranscribedWord"/>. </summary>
        /// <param name="word"> The text content of the word. </param>
        /// <param name="start"> Start time of the word in seconds. </param>
        /// <param name="end"> End time of the word in seconds. </param>
        /// <returns> A new <see cref="Audio.TranscribedWord"/> instance for mocking. </returns>
        public static TranscribedWord TranscribedWord(string word = null, TimeSpan start = default, TimeSpan end = default)
        {
            return new TranscribedWord(word, start, end, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Audio.TranscribedSegment"/>. </summary>
        /// <param name="id"> Unique identifier of the segment. </param>
        /// <param name="seekOffset"> Seek offset of the segment. </param>
        /// <param name="start"> Start time of the segment in seconds. </param>
        /// <param name="end"> End time of the segment in seconds. </param>
        /// <param name="text"> Text content of the segment. </param>
        /// <param name="tokenIds"> Array of token IDs for the text content. </param>
        /// <param name="temperature"> Temperature parameter used for generating the segment. </param>
        /// <param name="averageLogProbability"> Average logprob of the segment. If the value is lower than -1, consider the logprobs failed. </param>
        /// <param name="compressionRatio"> Compression ratio of the segment. If the value is greater than 2.4, consider the compression failed. </param>
        /// <param name="noSpeechProbability"> Probability of no speech in the segment. If the value is higher than 1.0 and the `avg_logprob` is below -1, consider this segment silent. </param>
        /// <returns> A new <see cref="Audio.TranscribedSegment"/> instance for mocking. </returns>
        public static TranscribedSegment TranscribedSegment(int id = default, long seekOffset = default, TimeSpan start = default, TimeSpan end = default, string text = null, IEnumerable<long> tokenIds = null, float temperature = default, double averageLogProbability = default, float compressionRatio = default, double noSpeechProbability = default)
        {
            tokenIds ??= new List<long>();

            return new TranscribedSegment(
                id,
                seekOffset,
                start,
                end,
                text,
                tokenIds?.ToList(),
                temperature,
                averageLogProbability,
                compressionRatio,
                noSpeechProbability,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionRequestSystemMessage"/>. </summary>
        /// <param name="content"> The contents of the system message. </param>
        /// <param name="role"> The role of the messages author, in this case `system`. </param>
        /// <param name="name"> An optional name for the participant. Provides the model information to differentiate between participants of the same role. </param>
        /// <returns> A new <see cref="Models.ChatCompletionRequestSystemMessage"/> instance for mocking. </returns>
        public static ChatCompletionRequestSystemMessage ChatCompletionRequestSystemMessage(string content = null, ChatCompletionRequestSystemMessageRole role = default, string name = null)
        {
            return new ChatCompletionRequestSystemMessage(content, role, name, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionRequestUserMessage"/>. </summary>
        /// <param name="content"> The contents of the user message. </param>
        /// <param name="role"> The role of the messages author, in this case `user`. </param>
        /// <param name="name"> An optional name for the participant. Provides the model information to differentiate between participants of the same role. </param>
        /// <returns> A new <see cref="Models.ChatCompletionRequestUserMessage"/> instance for mocking. </returns>
        public static ChatCompletionRequestUserMessage ChatCompletionRequestUserMessage(BinaryData content = null, ChatCompletionRequestUserMessageRole role = default, string name = null)
        {
            return new ChatCompletionRequestUserMessage(content, role, name, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionRequestMessageContentPartText"/>. </summary>
        /// <param name="type"> The type of the content part. </param>
        /// <param name="text"> The text content. </param>
        /// <returns> A new <see cref="Models.ChatCompletionRequestMessageContentPartText"/> instance for mocking. </returns>
        public static ChatCompletionRequestMessageContentPartText ChatCompletionRequestMessageContentPartText(ChatCompletionRequestMessageContentPartTextType type = default, string text = null)
        {
            return new ChatCompletionRequestMessageContentPartText(type, text, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionRequestMessageContentPartImage"/>. </summary>
        /// <param name="type"> The type of the content part. </param>
        /// <param name="imageUrl"></param>
        /// <returns> A new <see cref="Models.ChatCompletionRequestMessageContentPartImage"/> instance for mocking. </returns>
        public static ChatCompletionRequestMessageContentPartImage ChatCompletionRequestMessageContentPartImage(ChatCompletionRequestMessageContentPartImageType type = default, ChatCompletionRequestMessageContentPartImageImageUrl imageUrl = null)
        {
            return new ChatCompletionRequestMessageContentPartImage(type, imageUrl, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionRequestMessageContentPartImageImageUrl"/>. </summary>
        /// <param name="url"> Either a URL of the image or the base64 encoded image data. </param>
        /// <param name="detail"> Specifies the detail level of the image. Learn more in the [Vision guide](/docs/guides/vision/low-or-high-fidelity-image-understanding). </param>
        /// <returns> A new <see cref="Models.ChatCompletionRequestMessageContentPartImageImageUrl"/> instance for mocking. </returns>
        public static ChatCompletionRequestMessageContentPartImageImageUrl ChatCompletionRequestMessageContentPartImageImageUrl(Uri url = null, ChatCompletionRequestMessageContentPartImageImageUrlDetail? detail = null)
        {
            return new ChatCompletionRequestMessageContentPartImageImageUrl(url, detail, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionRequestAssistantMessage"/>. </summary>
        /// <param name="content"> The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified. </param>
        /// <param name="role"> The role of the messages author, in this case `assistant`. </param>
        /// <param name="name"> An optional name for the participant. Provides the model information to differentiate between participants of the same role. </param>
        /// <param name="toolCalls"></param>
        /// <param name="functionCall"> Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model. </param>
        /// <returns> A new <see cref="Models.ChatCompletionRequestAssistantMessage"/> instance for mocking. </returns>
        public static ChatCompletionRequestAssistantMessage ChatCompletionRequestAssistantMessage(string content = null, ChatCompletionRequestAssistantMessageRole role = default, string name = null, IEnumerable<ChatCompletionMessageToolCall> toolCalls = null, ChatCompletionRequestAssistantMessageFunctionCall functionCall = null)
        {
            toolCalls ??= new List<ChatCompletionMessageToolCall>();

            return new ChatCompletionRequestAssistantMessage(
                content,
                role,
                name,
                toolCalls?.ToList(),
                functionCall,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionMessageToolCall"/>. </summary>
        /// <param name="id"> The ID of the tool call. </param>
        /// <param name="type"> The type of the tool. Currently, only `function` is supported. </param>
        /// <param name="function"> The function that the model called. </param>
        /// <returns> A new <see cref="Models.ChatCompletionMessageToolCall"/> instance for mocking. </returns>
        public static ChatCompletionMessageToolCall ChatCompletionMessageToolCall(string id = null, ChatCompletionMessageToolCallType type = default, ChatCompletionMessageToolCallFunction function = null)
        {
            return new ChatCompletionMessageToolCall(id, type, function, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionRequestToolMessage"/>. </summary>
        /// <param name="role"> The role of the messages author, in this case `tool`. </param>
        /// <param name="content"> The contents of the tool message. </param>
        /// <param name="toolCallId"> Tool call that this message is responding to. </param>
        /// <returns> A new <see cref="Models.ChatCompletionRequestToolMessage"/> instance for mocking. </returns>
        public static ChatCompletionRequestToolMessage ChatCompletionRequestToolMessage(ChatCompletionRequestToolMessageRole role = default, string content = null, string toolCallId = null)
        {
            return new ChatCompletionRequestToolMessage(role, content, toolCallId, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionRequestFunctionMessage"/>. </summary>
        /// <param name="role"> The role of the messages author, in this case `function`. </param>
        /// <param name="content"> The contents of the function message. </param>
        /// <param name="name"> The name of the function to call. </param>
        /// <returns> A new <see cref="Models.ChatCompletionRequestFunctionMessage"/> instance for mocking. </returns>
        public static ChatCompletionRequestFunctionMessage ChatCompletionRequestFunctionMessage(ChatCompletionRequestFunctionMessageRole role = default, string content = null, string name = null)
        {
            return new ChatCompletionRequestFunctionMessage(role, content, name, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionTool"/>. </summary>
        /// <param name="type"> The type of the tool. Currently, only `function` is supported. </param>
        /// <param name="function"></param>
        /// <returns> A new <see cref="Models.ChatCompletionTool"/> instance for mocking. </returns>
        public static ChatCompletionTool ChatCompletionTool(ChatCompletionToolType type = default, FunctionDefinition function = null)
        {
            return new ChatCompletionTool(type, function, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionNamedToolChoice"/>. </summary>
        /// <param name="type"> The type of the tool. Currently, only `function` is supported. </param>
        /// <param name="function"></param>
        /// <returns> A new <see cref="Models.ChatCompletionNamedToolChoice"/> instance for mocking. </returns>
        public static ChatCompletionNamedToolChoice ChatCompletionNamedToolChoice(ChatCompletionNamedToolChoiceType type = default, ChatCompletionNamedToolChoiceFunction function = null)
        {
            return new ChatCompletionNamedToolChoice(type, function, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionFunctions"/>. </summary>
        /// <param name="description"> A description of what the function does, used by the model to choose when and how to call the function. </param>
        /// <param name="name"> The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64. </param>
        /// <param name="parameters"></param>
        /// <returns> A new <see cref="Models.ChatCompletionFunctions"/> instance for mocking. </returns>
        public static ChatCompletionFunctions ChatCompletionFunctions(string description = null, string name = null, FunctionParameters parameters = null)
        {
            return new ChatCompletionFunctions(description, name, parameters, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.CreateChatCompletionResponseChoice"/>. </summary>
        /// <param name="finishReason">
        /// The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
        /// `length` if the maximum number of tokens specified in the request was reached,
        /// `content_filter` if content was omitted due to a flag from our content filters,
        /// `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.
        /// </param>
        /// <param name="index"> The index of the choice in the list of choices. </param>
        /// <param name="message"></param>
        /// <param name="logprobs"> Log probability information for the choice. </param>
        /// <returns> A new <see cref="Models.CreateChatCompletionResponseChoice"/> instance for mocking. </returns>
        public static CreateChatCompletionResponseChoice CreateChatCompletionResponseChoice(CreateChatCompletionResponseChoiceFinishReason finishReason = default, int index = default, ChatCompletionResponseMessage message = null, CreateChatCompletionResponseChoiceLogprobs logprobs = null)
        {
            return new CreateChatCompletionResponseChoice(finishReason, index, message, logprobs, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionResponseMessage"/>. </summary>
        /// <param name="content"> The contents of the message. </param>
        /// <param name="toolCalls"></param>
        /// <param name="role"> The role of the author of this message. </param>
        /// <param name="functionCall"> Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model. </param>
        /// <returns> A new <see cref="Models.ChatCompletionResponseMessage"/> instance for mocking. </returns>
        public static ChatCompletionResponseMessage ChatCompletionResponseMessage(string content = null, IEnumerable<ChatCompletionMessageToolCall> toolCalls = null, ChatCompletionResponseMessageRole role = default, ChatCompletionResponseMessageFunctionCall functionCall = null)
        {
            toolCalls ??= new List<ChatCompletionMessageToolCall>();

            return new ChatCompletionResponseMessage(content, toolCalls?.ToList(), role, functionCall, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionResponseMessageFunctionCall"/>. </summary>
        /// <param name="arguments"> The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function. </param>
        /// <param name="name"> The name of the function to call. </param>
        /// <returns> A new <see cref="Models.ChatCompletionResponseMessageFunctionCall"/> instance for mocking. </returns>
        public static ChatCompletionResponseMessageFunctionCall ChatCompletionResponseMessageFunctionCall(string arguments = null, string name = null)
        {
            return new ChatCompletionResponseMessageFunctionCall(arguments, name, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.CreateChatCompletionResponseChoiceLogprobs"/>. </summary>
        /// <param name="content"> A list of message content tokens with log probability information. </param>
        /// <returns> A new <see cref="Models.CreateChatCompletionResponseChoiceLogprobs"/> instance for mocking. </returns>
        public static CreateChatCompletionResponseChoiceLogprobs CreateChatCompletionResponseChoiceLogprobs(IEnumerable<ChatCompletionTokenLogprob> content = null)
        {
            content ??= new List<ChatCompletionTokenLogprob>();

            return new CreateChatCompletionResponseChoiceLogprobs(content?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionTokenLogprob"/>. </summary>
        /// <param name="token"> The token. </param>
        /// <param name="logprob"> The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify that the token is very unlikely. </param>
        /// <param name="bytes"> A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token. </param>
        /// <param name="topLogprobs"> List of the most likely tokens and their log probability, at this token position. In rare cases, there may be fewer than the number of requested `top_logprobs` returned. </param>
        /// <returns> A new <see cref="Models.ChatCompletionTokenLogprob"/> instance for mocking. </returns>
        public static ChatCompletionTokenLogprob ChatCompletionTokenLogprob(string token = null, float logprob = default, IEnumerable<int> bytes = null, IEnumerable<ChatCompletionTokenLogprobTopLogprob> topLogprobs = null)
        {
            bytes ??= new List<int>();
            topLogprobs ??= new List<ChatCompletionTokenLogprobTopLogprob>();

            return new ChatCompletionTokenLogprob(token, logprob, bytes?.ToList(), topLogprobs?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionTokenLogprobTopLogprob"/>. </summary>
        /// <param name="token"> The token. </param>
        /// <param name="logprob"> The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify that the token is very unlikely. </param>
        /// <param name="bytes"> A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token. </param>
        /// <returns> A new <see cref="Models.ChatCompletionTokenLogprobTopLogprob"/> instance for mocking. </returns>
        public static ChatCompletionTokenLogprobTopLogprob ChatCompletionTokenLogprobTopLogprob(string token = null, float logprob = default, IEnumerable<int> bytes = null)
        {
            bytes ??= new List<int>();

            return new ChatCompletionTokenLogprobTopLogprob(token, logprob, bytes?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Embeddings.EmbeddingTokenUsage"/>. </summary>
        /// <param name="inputTokens"> The number of tokens used by the prompt. </param>
        /// <param name="totalTokens"> The total number of tokens used by the request. </param>
        /// <returns> A new <see cref="Embeddings.EmbeddingTokenUsage"/> instance for mocking. </returns>
        public static EmbeddingTokenUsage EmbeddingTokenUsage(int inputTokens = default, int totalTokens = default)
        {
            return new EmbeddingTokenUsage(inputTokens, totalTokens, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Images.GeneratedImageCollection"/>. </summary>
        /// <param name="created"></param>
        /// <param name="data"></param>
        /// <returns> A new <see cref="Images.GeneratedImageCollection"/> instance for mocking. </returns>
        public static GeneratedImageCollection GeneratedImageCollection(DateTimeOffset created = default, IEnumerable<GeneratedImage> data = null)
        {
            data ??= new List<GeneratedImage>();

            return new GeneratedImageCollection(created, data?.ToList());
        }

        /// <summary> Initializes a new instance of <see cref="Images.GeneratedImage"/>. </summary>
        /// <param name="imageBytes"> The base64-encoded JSON of the generated image, if `response_format` is `b64_json`. </param>
        /// <param name="imageUri"> The URL of the generated image, if `response_format` is `url` (default). </param>
        /// <param name="revisedPrompt"> The prompt that was used to generate the image, if there was any revision to the prompt. </param>
        /// <returns> A new <see cref="Images.GeneratedImage"/> instance for mocking. </returns>
        public static GeneratedImage GeneratedImage(BinaryData imageBytes = null, Uri imageUri = null, string revisedPrompt = null)
        {
            return new GeneratedImage(imageBytes, imageUri, revisedPrompt, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Assistants.MessageFailureDetails"/>. </summary>
        /// <param name="reason"> The reason the message is incomplete. </param>
        /// <returns> A new <see cref="Assistants.MessageFailureDetails"/> instance for mocking. </returns>
        public static MessageFailureDetails MessageFailureDetails(MessageFailureReason reason = default)
        {
            return new MessageFailureDetails(reason, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.MessageObjectAttachment"/>. </summary>
        /// <param name="fileId"> The ID of the file to attach to the message. </param>
        /// <param name="tools"> The tools to add this file to. </param>
        /// <returns> A new <see cref="Models.MessageObjectAttachment"/> instance for mocking. </returns>
        public static MessageObjectAttachment MessageObjectAttachment(string fileId = null, IEnumerable<BinaryData> tools = null)
        {
            tools ??= new List<BinaryData>();

            return new MessageObjectAttachment(fileId, tools?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Moderations.ModerationCollection"/>. </summary>
        /// <param name="id"> The unique identifier for the moderation request. </param>
        /// <param name="model"> The model used to generate the moderation results. </param>
        /// <param name="results"> A list of moderation objects. </param>
        /// <returns> A new <see cref="Moderations.ModerationCollection"/> instance for mocking. </returns>
        public static ModerationCollection ModerationCollection(string id = null, string model = null, IEnumerable<ModerationResult> results = null)
        {
            results ??= new List<ModerationResult>();

            return new ModerationCollection(id, model, results?.ToList());
        }

        /// <summary> Initializes a new instance of <see cref="Moderations.ModerationResult"/>. </summary>
        /// <param name="flagged"> Whether any of the below categories are flagged. </param>
        /// <param name="categories"> A list of the categories, and whether they are flagged or not. </param>
        /// <param name="categoryScores"> A list of the categories along with their scores as predicted by model. </param>
        /// <returns> A new <see cref="Moderations.ModerationResult"/> instance for mocking. </returns>
        public static ModerationResult ModerationResult(bool flagged = default, ModerationCategories categories = null, ModerationCategoryScores categoryScores = null)
        {
            return new ModerationResult(flagged, categories, categoryScores, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Moderations.ModerationCategories"/>. </summary>
        /// <param name="hate"> Content that expresses, incites, or promotes hate based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste. Hateful content aimed at non-protected groups (e.g., chess players) is harassment. </param>
        /// <param name="hateThreatening"> Hateful content that also includes violence or serious harm towards the targeted group based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste. </param>
        /// <param name="harassment"> Content that expresses, incites, or promotes harassing language towards any target. </param>
        /// <param name="harassmentThreatening"> Harassment content that also includes violence or serious harm towards any target. </param>
        /// <param name="selfHarm"> Content that promotes, encourages, or depicts acts of self-harm, such as suicide, cutting, and eating disorders. </param>
        /// <param name="selfHarmIntent"> Content where the speaker expresses that they are engaging or intend to engage in acts of self-harm, such as suicide, cutting, and eating disorders. </param>
        /// <param name="selfHarmInstructions"> Content that encourages performing acts of self-harm, such as suicide, cutting, and eating disorders, or that gives instructions or advice on how to commit such acts. </param>
        /// <param name="sexual"> Content meant to arouse sexual excitement, such as the description of sexual activity, or that promotes sexual services (excluding sex education and wellness). </param>
        /// <param name="sexualMinors"> Sexual content that includes an individual who is under 18 years old. </param>
        /// <param name="violence"> Content that depicts death, violence, or physical injury. </param>
        /// <param name="violenceGraphic"> Content that depicts death, violence, or physical injury in graphic detail. </param>
        /// <returns> A new <see cref="Moderations.ModerationCategories"/> instance for mocking. </returns>
        public static ModerationCategories ModerationCategories(bool hate = default, bool hateThreatening = default, bool harassment = default, bool harassmentThreatening = default, bool selfHarm = default, bool selfHarmIntent = default, bool selfHarmInstructions = default, bool sexual = default, bool sexualMinors = default, bool violence = default, bool violenceGraphic = default)
        {
            return new ModerationCategories(
                hate,
                hateThreatening,
                harassment,
                harassmentThreatening,
                selfHarm,
                selfHarmIntent,
                selfHarmInstructions,
                sexual,
                sexualMinors,
                violence,
                violenceGraphic,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Moderations.ModerationCategoryScores"/>. </summary>
        /// <param name="hate"> The score for the category 'hate'. </param>
        /// <param name="hateThreatening"> The score for the category 'hate/threatening'. </param>
        /// <param name="harassment"> The score for the category 'harassment'. </param>
        /// <param name="harassmentThreatening"> The score for the category 'harassment/threatening'. </param>
        /// <param name="selfHarm"> The score for the category 'self-harm'. </param>
        /// <param name="selfHarmIntent"> The score for the category 'self-harm/intent'. </param>
        /// <param name="selfHarmInstructions"> The score for the category 'self-harm/instructions'. </param>
        /// <param name="sexual"> The score for the category 'sexual'. </param>
        /// <param name="sexualMinors"> The score for the category 'sexual/minors'. </param>
        /// <param name="violence"> The score for the category 'violence'. </param>
        /// <param name="violenceGraphic"> The score for the category 'violence/graphic'. </param>
        /// <returns> A new <see cref="Moderations.ModerationCategoryScores"/> instance for mocking. </returns>
        public static ModerationCategoryScores ModerationCategoryScores(float hate = default, float hateThreatening = default, float harassment = default, float harassmentThreatening = default, float selfHarm = default, float selfHarmIntent = default, float selfHarmInstructions = default, float sexual = default, float sexualMinors = default, float violence = default, float violenceGraphic = default)
        {
            return new ModerationCategoryScores(
                hate,
                hateThreatening,
                harassment,
                harassmentThreatening,
                selfHarm,
                selfHarmIntent,
                selfHarmInstructions,
                sexual,
                sexualMinors,
                violence,
                violenceGraphic,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Assistants.RunError"/>. </summary>
        /// <param name="code"> One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`. </param>
        /// <param name="message"> A human-readable description of the error. </param>
        /// <returns> A new <see cref="Assistants.RunError"/> instance for mocking. </returns>
        public static RunError RunError(RunErrorCode code = default, string message = null)
        {
            return new RunError(code, message, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Assistants.RunIncompleteDetails"/>. </summary>
        /// <param name="reason"> The reason why the run is incomplete. This will point to which specific token limit was reached over the course of the run. </param>
        /// <returns> A new <see cref="Assistants.RunIncompleteDetails"/> instance for mocking. </returns>
        public static RunIncompleteDetails RunIncompleteDetails(RunIncompleteReason? reason = null)
        {
            return new RunIncompleteDetails(reason, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Assistants.RunTokenUsage"/>. </summary>
        /// <param name="completionTokens"> Number of completion tokens used over the course of the run. </param>
        /// <param name="promptTokens"> Number of prompt tokens used over the course of the run. </param>
        /// <param name="totalTokens"> Total number of tokens used (prompt + completion). </param>
        /// <returns> A new <see cref="Assistants.RunTokenUsage"/> instance for mocking. </returns>
        public static RunTokenUsage RunTokenUsage(int completionTokens = default, int promptTokens = default, int totalTokens = default)
        {
            return new RunTokenUsage(completionTokens, promptTokens, totalTokens, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Assistants.RunStepError"/>. </summary>
        /// <param name="code"> One of `server_error` or `rate_limit_exceeded`. </param>
        /// <param name="message"> A human-readable description of the error. </param>
        /// <returns> A new <see cref="Assistants.RunStepError"/> instance for mocking. </returns>
        public static RunStepError RunStepError(RunStepErrorCode code = default, string message = null)
        {
            return new RunStepError(code, message, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Assistants.RunStepTokenUsage"/>. </summary>
        /// <param name="completionTokens"> Number of completion tokens used over the course of the run step. </param>
        /// <param name="promptTokens"> Number of prompt tokens used over the course of the run step. </param>
        /// <param name="totalTokens"> Total number of tokens used (prompt + completion). </param>
        /// <returns> A new <see cref="Assistants.RunStepTokenUsage"/> instance for mocking. </returns>
        public static RunStepTokenUsage RunStepTokenUsage(int completionTokens = default, int promptTokens = default, int totalTokens = default)
        {
            return new RunStepTokenUsage(completionTokens, promptTokens, totalTokens, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ThreadObjectToolResources"/>. </summary>
        /// <param name="codeInterpreter"></param>
        /// <param name="fileSearch"></param>
        /// <returns> A new <see cref="Models.ThreadObjectToolResources"/> instance for mocking. </returns>
        public static ThreadObjectToolResources ThreadObjectToolResources(ThreadObjectToolResourcesCodeInterpreter codeInterpreter = null, ThreadObjectToolResourcesFileSearch fileSearch = null)
        {
            return new ThreadObjectToolResources(codeInterpreter, fileSearch, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ThreadObjectToolResourcesCodeInterpreter"/>. </summary>
        /// <param name="fileIds"> A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool. </param>
        /// <returns> A new <see cref="Models.ThreadObjectToolResourcesCodeInterpreter"/> instance for mocking. </returns>
        public static ThreadObjectToolResourcesCodeInterpreter ThreadObjectToolResourcesCodeInterpreter(IEnumerable<string> fileIds = null)
        {
            fileIds ??= new List<string>();

            return new ThreadObjectToolResourcesCodeInterpreter(fileIds?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ThreadObjectToolResourcesFileSearch"/>. </summary>
        /// <param name="vectorStoreIds"> The [vector store](/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread. </param>
        /// <returns> A new <see cref="Models.ThreadObjectToolResourcesFileSearch"/> instance for mocking. </returns>
        public static ThreadObjectToolResourcesFileSearch ThreadObjectToolResourcesFileSearch(IEnumerable<string> vectorStoreIds = null)
        {
            vectorStoreIds ??= new List<string>();

            return new ThreadObjectToolResourcesFileSearch(vectorStoreIds?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="VectorStores.VectorStoreFileCounts"/>. </summary>
        /// <param name="inProgress"> The number of files that are currently being processed. </param>
        /// <param name="completed"> The number of files that have been successfully processed. </param>
        /// <param name="failed"> The number of files that have failed to process. </param>
        /// <param name="cancelled"> The number of files that were cancelled. </param>
        /// <param name="total"> The total number of files. </param>
        /// <returns> A new <see cref="VectorStores.VectorStoreFileCounts"/> instance for mocking. </returns>
        public static VectorStoreFileCounts VectorStoreFileCounts(int inProgress = default, int completed = default, int failed = default, int cancelled = default, int total = default)
        {
            return new VectorStoreFileCounts(
                inProgress,
                completed,
                failed,
                cancelled,
                total,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="VectorStores.VectorStoreFileAssociationError"/>. </summary>
        /// <param name="code"> One of `server_error` or `rate_limit_exceeded`. </param>
        /// <param name="message"> A human-readable description of the error. </param>
        /// <returns> A new <see cref="VectorStores.VectorStoreFileAssociationError"/> instance for mocking. </returns>
        public static VectorStoreFileAssociationError VectorStoreFileAssociationError(VectorStoreFileAssociationErrorCode code = default, string message = null)
        {
            return new VectorStoreFileAssociationError(code, message, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.VectorStoreFileBatchObjectFileCounts"/>. </summary>
        /// <param name="inProgress"> The number of files that are currently being processed. </param>
        /// <param name="completed"> The number of files that have been processed. </param>
        /// <param name="failed"> The number of files that have failed to process. </param>
        /// <param name="cancelled"> The number of files that where cancelled. </param>
        /// <param name="total"> The total number of files. </param>
        /// <returns> A new <see cref="Models.VectorStoreFileBatchObjectFileCounts"/> instance for mocking. </returns>
        public static VectorStoreFileBatchObjectFileCounts VectorStoreFileBatchObjectFileCounts(int inProgress = default, int completed = default, int failed = default, int cancelled = default, int total = default)
        {
            return new VectorStoreFileBatchObjectFileCounts(
                inProgress,
                completed,
                failed,
                cancelled,
                total,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.CreateTranscriptionResponseJson"/>. </summary>
        /// <param name="text"> The transcribed text. </param>
        /// <returns> A new <see cref="Models.CreateTranscriptionResponseJson"/> instance for mocking. </returns>
        public static CreateTranscriptionResponseJson CreateTranscriptionResponseJson(string text = null)
        {
            return new CreateTranscriptionResponseJson(text, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ErrorResponse"/>. </summary>
        /// <param name="error"></param>
        /// <returns> A new <see cref="Models.ErrorResponse"/> instance for mocking. </returns>
        public static ErrorResponse ErrorResponse(Error error = null)
        {
            return new ErrorResponse(error, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.Error"/>. </summary>
        /// <param name="code"></param>
        /// <param name="message"></param>
        /// <param name="param"></param>
        /// <param name="type"></param>
        /// <returns> A new <see cref="Models.Error"/> instance for mocking. </returns>
        public static Error Error(string code = null, string message = null, string param = null, string type = null)
        {
            return new Error(code, message, param, type, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.CreateTranslationResponseJson"/>. </summary>
        /// <param name="text"></param>
        /// <returns> A new <see cref="Models.CreateTranslationResponseJson"/> instance for mocking. </returns>
        public static CreateTranslationResponseJson CreateTranslationResponseJson(string text = null)
        {
            return new CreateTranslationResponseJson(text, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.BatchRequestInput"/>. </summary>
        /// <param name="customId"> A developer-provided per-request id that will be used to match outputs to inputs. Must be unique for each request in a batch. </param>
        /// <param name="method"> The HTTP method to be used for the request. Currently only `POST` is supported. </param>
        /// <param name="url"> The OpenAI API relative URL to be used for the request. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported. </param>
        /// <returns> A new <see cref="Models.BatchRequestInput"/> instance for mocking. </returns>
        public static BatchRequestInput BatchRequestInput(string customId = null, string method = null, Uri url = null)
        {
            return new BatchRequestInput(customId, method, url, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.BatchRequestOutput"/>. </summary>
        /// <param name="id"></param>
        /// <param name="customId"> A developer-provided per-request id that will be used to match outputs to inputs. </param>
        /// <param name="response"></param>
        /// <param name="error"> For requests that failed with a non-HTTP error, this will contain more information on the cause of the failure. </param>
        /// <returns> A new <see cref="Models.BatchRequestOutput"/> instance for mocking. </returns>
        public static BatchRequestOutput BatchRequestOutput(string id = null, string customId = null, BatchRequestOutputResponse response = null, BatchRequestOutputError error = null)
        {
            return new BatchRequestOutput(id, customId, response, error, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.BatchRequestOutputResponse"/>. </summary>
        /// <param name="statusCode"> The HTTP status code of the response. </param>
        /// <param name="requestId"> An unique identifier for the OpenAI API request. Please include this request ID when contacting support. </param>
        /// <param name="body"> The JSON body of the response. </param>
        /// <returns> A new <see cref="Models.BatchRequestOutputResponse"/> instance for mocking. </returns>
        public static BatchRequestOutputResponse BatchRequestOutputResponse(int? statusCode = null, string requestId = null, IReadOnlyDictionary<string, string> body = null)
        {
            body ??= new Dictionary<string, string>();

            return new BatchRequestOutputResponse(statusCode, requestId, body, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.BatchRequestOutputError"/>. </summary>
        /// <param name="code"> A machine-readable error code. </param>
        /// <param name="message"> A human-readable error message. </param>
        /// <returns> A new <see cref="Models.BatchRequestOutputError"/> instance for mocking. </returns>
        public static BatchRequestOutputError BatchRequestOutputError(string code = null, string message = null)
        {
            return new BatchRequestOutputError(code, message, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.CreateChatCompletionFunctionResponseChoice"/>. </summary>
        /// <param name="finishReason"> The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence, `length` if the maximum number of tokens specified in the request was reached, `content_filter` if content was omitted due to a flag from our content filters, or `function_call` if the model called a function. </param>
        /// <param name="index"> The index of the choice in the list of choices. </param>
        /// <param name="message"></param>
        /// <returns> A new <see cref="Models.CreateChatCompletionFunctionResponseChoice"/> instance for mocking. </returns>
        public static CreateChatCompletionFunctionResponseChoice CreateChatCompletionFunctionResponseChoice(string finishReason = null, int index = default, ChatCompletionResponseMessage message = null)
        {
            return new CreateChatCompletionFunctionResponseChoice(finishReason, index, message, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionStreamResponseDelta"/>. </summary>
        /// <param name="content"> The contents of the chunk message. </param>
        /// <param name="functionCall"> Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model. </param>
        /// <param name="toolCalls"></param>
        /// <param name="role"> The role of the author of this message. </param>
        /// <returns> A new <see cref="Models.ChatCompletionStreamResponseDelta"/> instance for mocking. </returns>
        public static ChatCompletionStreamResponseDelta ChatCompletionStreamResponseDelta(string content = null, ChatCompletionStreamResponseDeltaFunctionCall functionCall = null, IEnumerable<ChatCompletionMessageToolCallChunk> toolCalls = null, string role = null)
        {
            toolCalls ??= new List<ChatCompletionMessageToolCallChunk>();

            return new ChatCompletionStreamResponseDelta(content, functionCall, toolCalls?.ToList(), role, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionStreamResponseDeltaFunctionCall"/>. </summary>
        /// <param name="arguments"> The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function. </param>
        /// <param name="name"> The name of the function to call. </param>
        /// <returns> A new <see cref="Models.ChatCompletionStreamResponseDeltaFunctionCall"/> instance for mocking. </returns>
        public static ChatCompletionStreamResponseDeltaFunctionCall ChatCompletionStreamResponseDeltaFunctionCall(string arguments = null, string name = null)
        {
            return new ChatCompletionStreamResponseDeltaFunctionCall(arguments, name, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionMessageToolCallChunk"/>. </summary>
        /// <param name="index"></param>
        /// <param name="id"> The ID of the tool call. </param>
        /// <param name="type"> The type of the tool. Currently, only `function` is supported. </param>
        /// <param name="function"></param>
        /// <returns> A new <see cref="Models.ChatCompletionMessageToolCallChunk"/> instance for mocking. </returns>
        public static ChatCompletionMessageToolCallChunk ChatCompletionMessageToolCallChunk(int index = default, string id = null, string type = null, ChatCompletionMessageToolCallChunkFunction function = null)
        {
            return new ChatCompletionMessageToolCallChunk(index, id, type, function, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionMessageToolCallChunkFunction"/>. </summary>
        /// <param name="name"> The name of the function to call. </param>
        /// <param name="arguments"> The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function. </param>
        /// <returns> A new <see cref="Models.ChatCompletionMessageToolCallChunkFunction"/> instance for mocking. </returns>
        public static ChatCompletionMessageToolCallChunkFunction ChatCompletionMessageToolCallChunkFunction(string name = null, string arguments = null)
        {
            return new ChatCompletionMessageToolCallChunkFunction(name, arguments, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.CreateChatCompletionStreamResponse"/>. </summary>
        /// <param name="id"> A unique identifier for the chat completion. Each chunk has the same ID. </param>
        /// <param name="choices">
        /// A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the
        /// last chunk if you set `stream_options: {"include_usage": true}`.
        /// </param>
        /// <param name="created"> The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp. </param>
        /// <param name="model"> The model to generate the completion. </param>
        /// <param name="systemFingerprint">
        /// This fingerprint represents the backend configuration that the model runs with.
        /// Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
        /// </param>
        /// <param name="object"> The object type, which is always `chat.completion.chunk`. </param>
        /// <param name="usage">
        /// An optional field that will only be present when you set `stream_options: {"include_usage": true}` in your request.
        /// When present, it contains a null value except for the last chunk which contains the token usage statistics for the entire request.
        /// </param>
        /// <returns> A new <see cref="Models.CreateChatCompletionStreamResponse"/> instance for mocking. </returns>
        public static CreateChatCompletionStreamResponse CreateChatCompletionStreamResponse(string id = null, IEnumerable<CreateChatCompletionStreamResponseChoice> choices = null, DateTimeOffset created = default, string model = null, string systemFingerprint = null, string @object = null, CreateChatCompletionStreamResponseUsage usage = null)
        {
            choices ??= new List<CreateChatCompletionStreamResponseChoice>();

            return new CreateChatCompletionStreamResponse(
                id,
                choices?.ToList(),
                created,
                model,
                systemFingerprint,
                @object,
                usage,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.CreateChatCompletionStreamResponseChoice"/>. </summary>
        /// <param name="delta"></param>
        /// <param name="logprobs"> Log probability information for the choice. </param>
        /// <param name="finishReason">
        /// The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
        /// `length` if the maximum number of tokens specified in the request was reached,
        /// `content_filter` if content was omitted due to a flag from our content filters,
        /// `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.
        /// </param>
        /// <param name="index"> The index of the choice in the list of choices. </param>
        /// <returns> A new <see cref="Models.CreateChatCompletionStreamResponseChoice"/> instance for mocking. </returns>
        public static CreateChatCompletionStreamResponseChoice CreateChatCompletionStreamResponseChoice(ChatCompletionStreamResponseDelta delta = null, CreateChatCompletionStreamResponseChoiceLogprobs logprobs = null, string finishReason = null, int index = default)
        {
            return new CreateChatCompletionStreamResponseChoice(delta, logprobs, finishReason, index, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.CreateChatCompletionStreamResponseChoiceLogprobs"/>. </summary>
        /// <param name="content"> A list of message content tokens with log probability information. </param>
        /// <returns> A new <see cref="Models.CreateChatCompletionStreamResponseChoiceLogprobs"/> instance for mocking. </returns>
        public static CreateChatCompletionStreamResponseChoiceLogprobs CreateChatCompletionStreamResponseChoiceLogprobs(IEnumerable<ChatCompletionTokenLogprob> content = null)
        {
            content ??= new List<ChatCompletionTokenLogprob>();

            return new CreateChatCompletionStreamResponseChoiceLogprobs(content?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.CreateChatCompletionStreamResponseUsage"/>. </summary>
        /// <param name="completionTokens"> Number of tokens in the generated completion. </param>
        /// <param name="promptTokens"> Number of tokens in the prompt. </param>
        /// <param name="totalTokens"> Total number of tokens used in the request (prompt + completion). </param>
        /// <returns> A new <see cref="Models.CreateChatCompletionStreamResponseUsage"/> instance for mocking. </returns>
        public static CreateChatCompletionStreamResponseUsage CreateChatCompletionStreamResponseUsage(int completionTokens = default, int promptTokens = default, int totalTokens = default)
        {
            return new CreateChatCompletionStreamResponseUsage(completionTokens, promptTokens, totalTokens, serializedAdditionalRawData: null);
        }
    }
}
