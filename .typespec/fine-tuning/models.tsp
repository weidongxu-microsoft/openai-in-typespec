/*
 * This file was automatically generated from an OpenAPI .yaml file.
 * Edits made directly to this file will be lost.
 */

import "../chat";
import "../common";
import "./custom.tsp";

using TypeSpec.OpenAPI;

namespace OpenAI;

// Tool generated type. Extracts CreateFineTuningJobRequest.integrations
model CreateFineTuningJobRequestIntegrations
  is CreateFineTuningJobRequestIntegration[];

// Tool generated type. Extracts FineTuningJob.integrations
@maxItems(5)
@extension("x-oaiExpandable", true)
model FineTuningJobIntegrations is FineTuningIntegration[];

model CreateFineTuningJobRequest {
  /**
   * The name of the model to fine-tune. You can select one of the
   * [supported models](/docs/guides/fine-tuning/which-models-can-be-fine-tuned).
   */
  @extension("x-oaiTypeLabel", "string")
  `model`:
    | string
    | "babbage-002"
    | "davinci-002"
    | "gpt-3.5-turbo"
    | "gpt-4o-mini";

  @doc("""
    The ID of an uploaded file that contains training data.
    
    See [upload file](/docs/api-reference/files/create) for how to upload a file.
    
    Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose `fine-tune`.
    
    The contents of the file should differ depending on if the model uses the [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) format.
    
    See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.
    """)
  training_file: string;

  // Tool customization: reflect observed wire truth (learning_rate_multiplier, n_epochs) for hyperparameters in ft responses
  /** The hyperparameters used for the fine-tuning job. */
  hyperparameters?: CreateFineTuningJobRequestHyperparameters;

  @doc("""
    A string of up to 64 characters that will be added to your fine-tuned model name.
    
    For example, a `suffix` of "custom-model-name" would produce a model name like `ft:gpt-4o-mini:openai:custom-model-name:7p4lURel`.
    """)
  @minLength(1)
  @maxLength(64)
  suffix?: string | null = null;

  @doc("""
    The ID of an uploaded file that contains validation data.
    
    If you provide this file, the data is used to generate validation
    metrics periodically during fine-tuning. These metrics can be viewed in
    the fine-tuning results file.
    The same data should not be present in both train and validation files.
    
    Your dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.
    
    See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.
    """)
  validation_file?: string | null;

  // Tool customization: establish a discriminated type basis
  /** A list of integrations to enable for your fine-tuning job. */
  integrations?: CreateFineTuningJobRequestIntegrations | null;

  /**
   * The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases.
   * If a seed is not specified, one will be generated for you.
   */
  @minValue(0)
  @maxValue(2147483647)
  seed?: int32 | null;
}

model ListPaginatedFineTuningJobsResponse {
  data: FineTuningJob[];
  has_more: boolean;
  object: "list";
}

// Tool customization: Include spec-omitted 'has_more' property
model ListFineTuningJobEventsResponse {
  has_more: boolean;
  data: FineTuningJobEvent[];
  object: "list";
}

model ListFineTuningJobCheckpointsResponse {
  data: FineTuningJobCheckpoint[];
  object: "list";
  first_id?: string | null;
  last_id?: string | null;
  has_more: boolean;
}

// Tool customization: Represent undocumented response 'user_provided_suffix' property
@doc("""
  The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.
  """)
model FineTuningJob {
  /** The descriptive suffix applied to the job, as specified in the job creation request. */
  user_provided_suffix?: string | null;

  /** The object identifier, which can be referenced in the API endpoints. */
  id: string;

  // Tool customization: 'created' and fields ending in '_at' are Unix encoded utcDateTime
  /** The Unix timestamp (in seconds) for when the fine-tuning job was created. */
  @encode("unixTimestamp", int32)
  created_at: utcDateTime;

  @doc("""
    For fine-tuning jobs that have `failed`, this will contain more information on the cause of the failure.
    """)
  error: {
    /** A machine-readable error code. */
    code: string;

    /** A human-readable error message. */
    message: string;

    @doc("""
      The parameter that was invalid, usually `training_file` or `validation_file`. This field will be null if the failure was not parameter-specific.
      """)
    param: string | null;
  } | null;

  /** The name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running. */
  fine_tuned_model: string | null;

  // Tool customization: 'created' and fields ending in '_at' are Unix encoded utcDateTime
  /** The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running. */
  @encode("unixTimestamp", int32)
  finished_at: utcDateTime | null;

  // Tool customization: reflect observed wire truth (learning_rate_multiplier, n_epochs) for hyperparameters in ft responses
  /** The hyperparameters used for the fine-tuning job. See the [fine-tuning guide](/docs/guides/fine-tuning) for more details. */
  hyperparameters: FineTuningJobHyperparameters;

  /** The base model that is being fine-tuned. */
  `model`: string;

  /** The object type, which is always "fine_tuning.job". */
  object: "fine_tuning.job";

  /** The organization that owns the fine-tuning job. */
  organization_id: string;

  /** The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the [Files API](/docs/api-reference/files/retrieve-contents). */
  result_files: string[];

  @doc("""
    The current status of the fine-tuning job, which can be either `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.
    """)
  status:
    | "validating_files"
    | "queued"
    | "running"
    | "succeeded"
    | "failed"
    | "cancelled";

  /** The total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running. */
  trained_tokens: int32 | null;

  /** The file ID used for training. You can retrieve the training data with the [Files API](/docs/api-reference/files/retrieve-contents). */
  training_file: string;

  /** The file ID used for validation. You can retrieve the validation results with the [Files API](/docs/api-reference/files/retrieve-contents). */
  validation_file: string | null;

  /** A list of integrations to enable for this fine-tuning job. */
  integrations?: FineTuningJobIntegrations | null;

  /** The seed used for the fine-tuning job. */
  seed: int32;

  // Tool customization: 'created' and fields ending in '_at' are Unix encoded utcDateTime
  /** The Unix timestamp (in seconds) for when the fine-tuning job is estimated to finish. The value will be null if the fine-tuning job is not running. */
  @encode("unixTimestamp", int32)
  estimated_finish?: utcDateTime | null;
}

// Tool customization: Convert to instantiation of discriminated type
model FineTuningIntegrationWandb extends FineTuningIntegration {
  /** The type of the integration being enabled for the fine-tuning job */
  type: "wandb";

  /**
   * The settings for your integration with Weights and Biases. This payload specifies the project that
   * metrics will be sent to. Optionally, you can set an explicit display name for your run, add tags
   * to your run, and set a default entity (team, username, etc) to be associated with your run.
   */
  wandb: {
    /** The name of the project that the new run will be created under. */
    project: string;

    /** A display name to set for the run. If not set, we will use the Job ID as the name. */
    name?: string | null;

    /**
     * The entity to use for the run. This allows you to set the team or username of the WandB user that you would
     * like associated with the run. If not set, the default entity for the registered WandB API key is used.
     */
    entity?: string | null;

    /**
     * A list of tags to be attached to the newly created run. These tags are passed through directly to WandB. Some
     * default tags are generated by OpenAI: "openai/finetune", "openai/{base-model}", "openai/{ftjob-abcdef}".
     */
    tags?: string[];
  };
}

/** Fine-tuning job event object */
model FineTuningJobEvent {
  id: string;

  // Tool customization: 'created' and fields ending in '_at' are Unix encoded utcDateTime
  @encode("unixTimestamp", int32)
  created_at: utcDateTime;

  level: "info" | "warn" | "error";
  message: string;
  object: "fine_tuning.job.event";
}

@doc("""
  The `fine_tuning.job.checkpoint` object represents a model checkpoint for a fine-tuning job that is ready to use.
  """)
model FineTuningJobCheckpoint {
  /** The checkpoint identifier, which can be referenced in the API endpoints. */
  id: string;

  // Tool customization: 'created' and fields ending in '_at' are Unix encoded utcDateTime
  /** The Unix timestamp (in seconds) for when the checkpoint was created. */
  @encode("unixTimestamp", int32)
  created_at: utcDateTime;

  /** The name of the fine-tuned checkpoint model that is created. */
  fine_tuned_model_checkpoint: string;

  /** The step number that the checkpoint was created at. */
  step_number: int32;

  /** Metrics at the step number during the fine-tuning job. */
  metrics: {
    step?: float32;
    train_loss?: float32;
    train_mean_token_accuracy?: float32;
    valid_loss?: float32;
    valid_mean_token_accuracy?: float32;
    full_valid_loss?: float32;
    full_valid_mean_token_accuracy?: float32;
  };

  /** The name of the fine-tuning job that this checkpoint was created from. */
  fine_tuning_job_id: string;

  /** The object type, which is always "fine_tuning.job.checkpoint". */
  object: "fine_tuning.job.checkpoint";
}

/** The per-line training example of a fine-tuning input file for chat models */
model FinetuneChatRequestInput {
  @minItems(1)
  @extension("x-oaiExpandable", true)
  messages?: (
    | ChatCompletionRequestSystemMessage
    | ChatCompletionRequestUserMessage
    | FineTuneChatCompletionRequestAssistantMessage
    | ChatCompletionRequestToolMessage
    | ChatCompletionRequestFunctionMessage)[];

  /** A list of tools the model may generate JSON inputs for. */
  tools?: ChatCompletionTool[];

  parallel_tool_calls?: ParallelToolCalls = true;

  /** A list of functions the model may generate JSON inputs for. */
  #deprecated "This field is marked as deprecated."
  @minItems(1)
  @maxItems(128)
  functions?: ChatCompletionFunctions[];
}

/** The per-line training example of a fine-tuning input file for completions models */
model FinetuneCompletionRequestInput {
  /** The input prompt for this training example. */
  prompt?: string;

  /** The desired completion for this training example. */
  completion?: string;
}

model FineTuneChatCompletionRequestAssistantMessage
  extends ChatCompletionRequestAssistantMessage {}
