// Code generated by Microsoft (R) TypeSpec Code Generator.

package com.openai;

import com.generic.core.annotation.Metadata;
import com.generic.core.annotation.ServiceClient;
import com.generic.core.http.Response;
import com.generic.core.http.exception.HttpResponseException;
import com.generic.core.http.models.RequestOptions;
import com.generic.core.models.BinaryData;
import com.openai.implementation.ChatsImpl;
import com.openai.models.CreateChatCompletionRequest;
import com.openai.models.CreateChatCompletionResponse;

/**
 * Initializes a new instance of the synchronous OpenAIClient type.
 */
@ServiceClient(builder = OpenAIClientBuilder.class)
public final class ChatClient {
    @Metadata(generated = true)
    private final ChatsImpl serviceClient;

    /**
     * Initializes an instance of ChatClient class.
     * 
     * @param serviceClient the service client implementation.
     */
    @Metadata(generated = true)
    ChatClient(ChatsImpl serviceClient) {
        this.serviceClient = serviceClient;
    }

    /**
     * Creates a model response for the given chat conversation.
     * <p><strong>Request Body Schema</strong></p>
     * 
     * <pre>{@code
     * {
     *     messages (Required): [
     *         BinaryData (Required)
     *     ]
     *     model: String(gpt-4-0125-preview/gpt-4-turbo-preview/gpt-4-1106-preview/gpt-4-vision-preview/gpt-4/gpt-4-0314/gpt-4-0613/gpt-4-32k/gpt-4-32k-0314/gpt-4-32k-0613/gpt-3.5-turbo/gpt-3.5-turbo-16k/gpt-3.5-turbo-0301/gpt-3.5-turbo-0613/gpt-3.5-turbo-1106/gpt-3.5-turbo-0125/gpt-3.5-turbo-16k-0613) (Required)
     *     frequency_penalty: Double (Optional)
     *     logit_bias (Optional): {
     *         String: long (Required)
     *     }
     *     logprobs: Boolean (Optional)
     *     top_logprobs: Long (Optional)
     *     max_tokens: Long (Optional)
     *     n: Long (Optional)
     *     presence_penalty: Double (Optional)
     *     response_format (Optional): {
     *         type: String(text/json_object) (Optional)
     *     }
     *     seed: Long (Optional)
     *     stop: BinaryData (Optional)
     *     stream: Boolean (Optional)
     *     temperature: Double (Optional)
     *     top_p: Double (Optional)
     *     tools (Optional): [
     *          (Optional){
     *             type: String (Required)
     *             function (Required): {
     *                 description: String (Optional)
     *                 name: String (Required)
     *                 parameters (Optional): {
     *                     String: Object (Required)
     *                 }
     *             }
     *         }
     *     ]
     *     tool_choice: BinaryData (Optional)
     *     user: String (Optional)
     *     function_call: BinaryData (Optional)
     *     functions (Optional): [
     *          (Optional){
     *             description: String (Optional)
     *             name: String (Required)
     *             parameters (Optional): {
     *                 String: Object (Required)
     *             }
     *         }
     *     ]
     * }
     * }</pre>
     * 
     * <p><strong>Response Body Schema</strong></p>
     * 
     * <pre>{@code
     * {
     *     id: String (Required)
     *     choices (Required): [
     *          (Required){
     *             finish_reason: String(stop/length/tool_calls/content_filter/function_call) (Required)
     *             index: long (Required)
     *             message (Required): {
     *                 content: String (Required)
     *                 tool_calls (Optional): [
     *                      (Optional){
     *                         id: String (Required)
     *                         type: String (Required)
     *                         function (Required): {
     *                             name: String (Required)
     *                             arguments: String (Required)
     *                         }
     *                     }
     *                 ]
     *                 role: String (Required)
     *                 function_call (Optional): {
     *                     arguments: String (Required)
     *                     name: String (Required)
     *                 }
     *             }
     *             logprobs (Required): {
     *                 content (Required): [
     *                      (Required){
     *                         token: String (Required)
     *                         logprob: double (Required)
     *                         bytes (Required): [
     *                             long (Required)
     *                         ]
     *                         top_logprobs (Required): [
     *                              (Required){
     *                                 token: String (Required)
     *                                 logprob: double (Required)
     *                                 bytes (Required): [
     *                                     long (Required)
     *                                 ]
     *                             }
     *                         ]
     *                     }
     *                 ]
     *             }
     *         }
     *     ]
     *     created: long (Required)
     *     model: String (Required)
     *     system_fingerprint: String (Optional)
     *     object: String (Required)
     *     usage (Optional): {
     *         prompt_tokens: long (Required)
     *         completion_tokens: long (Required)
     *         total_tokens: long (Required)
     *     }
     * }
     * }</pre>
     * 
     * @param createChatCompletionRequest The createChatCompletionRequest parameter.
     * @param requestOptions The options to configure the HTTP request before HTTP client sends it.
     * @throws HttpResponseException thrown if the service returns an error.
     * @return represents a chat completion response returned by model, based on the provided input.
     */
    @Metadata(generated = true)
    public Response<BinaryData> createChatCompletionWithResponse(BinaryData createChatCompletionRequest,
        RequestOptions requestOptions) {
        return this.serviceClient.createChatCompletionWithResponse(createChatCompletionRequest, requestOptions);
    }

    /**
     * Creates a model response for the given chat conversation.
     * 
     * @param createChatCompletionRequest The createChatCompletionRequest parameter.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws HttpResponseException thrown if the service returns an error.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return represents a chat completion response returned by model, based on the provided input.
     */
    @Metadata(generated = true)
    public CreateChatCompletionResponse createChatCompletion(CreateChatCompletionRequest createChatCompletionRequest) {
        // Generated convenience method for createChatCompletionWithResponse
        RequestOptions requestOptions = new RequestOptions();
        return createChatCompletionWithResponse(BinaryData.fromObject(createChatCompletionRequest), requestOptions)
            .getValue()
            .toObject(CreateChatCompletionResponse.class);
    }
}
