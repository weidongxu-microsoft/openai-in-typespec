// Code generated by Microsoft (R) TypeSpec Code Generator.

package com.openai.models;

import io.clientcore.core.annotation.Metadata;
import io.clientcore.core.annotation.TypeConditions;
import io.clientcore.core.json.JsonReader;
import io.clientcore.core.json.JsonSerializable;
import io.clientcore.core.json.JsonToken;
import io.clientcore.core.json.JsonWriter;
import io.clientcore.core.util.binarydata.BinaryData;
import java.io.IOException;
import java.util.List;
import java.util.Map;

/**
 * The CreateRunRequest model.
 */
@Metadata(conditions = { TypeConditions.FLUENT })
public final class CreateRunRequest implements JsonSerializable<CreateRunRequest> {
    /*
     * The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.
     */
    @Metadata(generated = true)
    private final String assistantId;

    /*
     * The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it
     * will override the model associated with the assistant. If not, the model associated with the assistant will be
     * used.
     */
    @Metadata(generated = true)
    private CreateRunRequestModel model;

    /*
     * Overrides the [instructions](/docs/api-reference/assistants/createAssistant) of the assistant. This is useful for
     * modifying the behavior on a per-run basis.
     */
    @Metadata(generated = true)
    private String instructions;

    /*
     * Appends additional instructions at the end of the instructions for the run. This is useful for modifying the
     * behavior on a per-run basis without overriding other instructions.
     */
    @Metadata(generated = true)
    private String additionalInstructions;

    /*
     * Adds additional messages to the thread before creating the run.
     */
    @Metadata(generated = true)
    private List<CreateMessageRequest> additionalMessages;

    /*
     * Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run
     * basis.
     */
    @Metadata(generated = true)
    private List<AssistantToolDefinition> tools;

    /*
     * Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional
     * information about the object in a structured format. Keys can be a maximum of 64 characters long and values can
     * be a maximum of 512 characters long.
     */
    @Metadata(generated = true)
    private Map<String, String> metadata;

    /*
     * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while
     * lower values like 0.2 will make it more focused and deterministic.
     */
    @Metadata(generated = true)
    private Double temperature;

    /*
     * An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of
     * the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are
     * considered.
     * 
     * We generally recommend altering this or temperature but not both.
     */
    @Metadata(generated = true)
    private Double topP;

    /*
     * If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run
     * enters a terminal state with a `data: [DONE]` message.
     */
    @Metadata(generated = true)
    private Boolean stream;

    /*
     * The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort
     * to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the
     * number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more
     * info.
     */
    @Metadata(generated = true)
    private Integer maxPromptTokens;

    /*
     * The maximum number of completion tokens that may be used over the course of the run. The run will make a best
     * effort to use only the number of completion tokens specified, across multiple turns of the run. If the run
     * exceeds the number of completion tokens specified, the run will end with status `incomplete`. See
     * `incomplete_details` for more info.
     */
    @Metadata(generated = true)
    private Integer maxCompletionTokens;

    /*
     * The truncation_strategy property.
     */
    @Metadata(generated = true)
    private TruncationObject truncationStrategy;

    /*
     * The tool_choice property.
     */
    @Metadata(generated = true)
    private BinaryData toolChoice;

    /*
     * The parallel_tool_calls property.
     */
    @Metadata(generated = true)
    private Boolean parallelToolCalls;

    /*
     * The response_format property.
     */
    @Metadata(generated = true)
    private BinaryData responseFormat;

    /**
     * Creates an instance of CreateRunRequest class.
     * 
     * @param assistantId the assistantId value to set.
     */
    @Metadata(generated = true)
    public CreateRunRequest(String assistantId) {
        this.assistantId = assistantId;
    }

    /**
     * Get the assistantId property: The ID of the [assistant](/docs/api-reference/assistants) to use to execute this
     * run.
     * 
     * @return the assistantId value.
     */
    @Metadata(generated = true)
    public String getAssistantId() {
        return this.assistantId;
    }

    /**
     * Get the model property: The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a
     * value is provided here, it will override the model associated with the assistant. If not, the model associated
     * with the assistant will be used.
     * 
     * @return the model value.
     */
    @Metadata(generated = true)
    public CreateRunRequestModel getModel() {
        return this.model;
    }

    /**
     * Set the model property: The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a
     * value is provided here, it will override the model associated with the assistant. If not, the model associated
     * with the assistant will be used.
     * 
     * @param model the model value to set.
     * @return the CreateRunRequest object itself.
     */
    @Metadata(generated = true)
    public CreateRunRequest setModel(CreateRunRequestModel model) {
        this.model = model;
        return this;
    }

    /**
     * Get the instructions property: Overrides the [instructions](/docs/api-reference/assistants/createAssistant) of
     * the assistant. This is useful for modifying the behavior on a per-run basis.
     * 
     * @return the instructions value.
     */
    @Metadata(generated = true)
    public String getInstructions() {
        return this.instructions;
    }

    /**
     * Set the instructions property: Overrides the [instructions](/docs/api-reference/assistants/createAssistant) of
     * the assistant. This is useful for modifying the behavior on a per-run basis.
     * 
     * @param instructions the instructions value to set.
     * @return the CreateRunRequest object itself.
     */
    @Metadata(generated = true)
    public CreateRunRequest setInstructions(String instructions) {
        this.instructions = instructions;
        return this;
    }

    /**
     * Get the additionalInstructions property: Appends additional instructions at the end of the instructions for the
     * run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.
     * 
     * @return the additionalInstructions value.
     */
    @Metadata(generated = true)
    public String getAdditionalInstructions() {
        return this.additionalInstructions;
    }

    /**
     * Set the additionalInstructions property: Appends additional instructions at the end of the instructions for the
     * run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.
     * 
     * @param additionalInstructions the additionalInstructions value to set.
     * @return the CreateRunRequest object itself.
     */
    @Metadata(generated = true)
    public CreateRunRequest setAdditionalInstructions(String additionalInstructions) {
        this.additionalInstructions = additionalInstructions;
        return this;
    }

    /**
     * Get the additionalMessages property: Adds additional messages to the thread before creating the run.
     * 
     * @return the additionalMessages value.
     */
    @Metadata(generated = true)
    public List<CreateMessageRequest> getAdditionalMessages() {
        return this.additionalMessages;
    }

    /**
     * Set the additionalMessages property: Adds additional messages to the thread before creating the run.
     * 
     * @param additionalMessages the additionalMessages value to set.
     * @return the CreateRunRequest object itself.
     */
    @Metadata(generated = true)
    public CreateRunRequest setAdditionalMessages(List<CreateMessageRequest> additionalMessages) {
        this.additionalMessages = additionalMessages;
        return this;
    }

    /**
     * Get the tools property: Override the tools the assistant can use for this run. This is useful for modifying the
     * behavior on a per-run basis.
     * 
     * @return the tools value.
     */
    @Metadata(generated = true)
    public List<AssistantToolDefinition> getTools() {
        return this.tools;
    }

    /**
     * Set the tools property: Override the tools the assistant can use for this run. This is useful for modifying the
     * behavior on a per-run basis.
     * 
     * @param tools the tools value to set.
     * @return the CreateRunRequest object itself.
     */
    @Metadata(generated = true)
    public CreateRunRequest setTools(List<AssistantToolDefinition> tools) {
        this.tools = tools;
        return this;
    }

    /**
     * Get the metadata property: Set of 16 key-value pairs that can be attached to an object. This can be useful for
     * storing additional information about the object in a structured format. Keys can be a maximum of 64 characters
     * long and values can be a maximum of 512 characters long.
     * 
     * @return the metadata value.
     */
    @Metadata(generated = true)
    public Map<String, String> getMetadata() {
        return this.metadata;
    }

    /**
     * Set the metadata property: Set of 16 key-value pairs that can be attached to an object. This can be useful for
     * storing additional information about the object in a structured format. Keys can be a maximum of 64 characters
     * long and values can be a maximum of 512 characters long.
     * 
     * @param metadata the metadata value to set.
     * @return the CreateRunRequest object itself.
     */
    @Metadata(generated = true)
    public CreateRunRequest setMetadata(Map<String, String> metadata) {
        this.metadata = metadata;
        return this;
    }

    /**
     * Get the temperature property: What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make
     * the output more random, while lower values like 0.2 will make it more focused and deterministic.
     * 
     * @return the temperature value.
     */
    @Metadata(generated = true)
    public Double getTemperature() {
        return this.temperature;
    }

    /**
     * Set the temperature property: What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make
     * the output more random, while lower values like 0.2 will make it more focused and deterministic.
     * 
     * @param temperature the temperature value to set.
     * @return the CreateRunRequest object itself.
     */
    @Metadata(generated = true)
    public CreateRunRequest setTemperature(Double temperature) {
        this.temperature = temperature;
        return this;
    }

    /**
     * Get the topP property: An alternative to sampling with temperature, called nucleus sampling, where the model
     * considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top
     * 10% probability mass are considered.
     * 
     * We generally recommend altering this or temperature but not both.
     * 
     * @return the topP value.
     */
    @Metadata(generated = true)
    public Double getTopP() {
        return this.topP;
    }

    /**
     * Set the topP property: An alternative to sampling with temperature, called nucleus sampling, where the model
     * considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top
     * 10% probability mass are considered.
     * 
     * We generally recommend altering this or temperature but not both.
     * 
     * @param topP the topP value to set.
     * @return the CreateRunRequest object itself.
     */
    @Metadata(generated = true)
    public CreateRunRequest setTopP(Double topP) {
        this.topP = topP;
        return this;
    }

    /**
     * Get the stream property: If `true`, returns a stream of events that happen during the Run as server-sent events,
     * terminating when the Run enters a terminal state with a `data: [DONE]` message.
     * 
     * @return the stream value.
     */
    @Metadata(generated = true)
    public Boolean isStream() {
        return this.stream;
    }

    /**
     * Set the stream property: If `true`, returns a stream of events that happen during the Run as server-sent events,
     * terminating when the Run enters a terminal state with a `data: [DONE]` message.
     * 
     * @param stream the stream value to set.
     * @return the CreateRunRequest object itself.
     */
    @Metadata(generated = true)
    public CreateRunRequest setStream(Boolean stream) {
        this.stream = stream;
        return this;
    }

    /**
     * Get the maxPromptTokens property: The maximum number of prompt tokens that may be used over the course of the
     * run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of
     * the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See
     * `incomplete_details` for more info.
     * 
     * @return the maxPromptTokens value.
     */
    @Metadata(generated = true)
    public Integer getMaxPromptTokens() {
        return this.maxPromptTokens;
    }

    /**
     * Set the maxPromptTokens property: The maximum number of prompt tokens that may be used over the course of the
     * run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of
     * the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See
     * `incomplete_details` for more info.
     * 
     * @param maxPromptTokens the maxPromptTokens value to set.
     * @return the CreateRunRequest object itself.
     */
    @Metadata(generated = true)
    public CreateRunRequest setMaxPromptTokens(Integer maxPromptTokens) {
        this.maxPromptTokens = maxPromptTokens;
        return this;
    }

    /**
     * Get the maxCompletionTokens property: The maximum number of completion tokens that may be used over the course of
     * the run. The run will make a best effort to use only the number of completion tokens specified, across multiple
     * turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status
     * `incomplete`. See `incomplete_details` for more info.
     * 
     * @return the maxCompletionTokens value.
     */
    @Metadata(generated = true)
    public Integer getMaxCompletionTokens() {
        return this.maxCompletionTokens;
    }

    /**
     * Set the maxCompletionTokens property: The maximum number of completion tokens that may be used over the course of
     * the run. The run will make a best effort to use only the number of completion tokens specified, across multiple
     * turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status
     * `incomplete`. See `incomplete_details` for more info.
     * 
     * @param maxCompletionTokens the maxCompletionTokens value to set.
     * @return the CreateRunRequest object itself.
     */
    @Metadata(generated = true)
    public CreateRunRequest setMaxCompletionTokens(Integer maxCompletionTokens) {
        this.maxCompletionTokens = maxCompletionTokens;
        return this;
    }

    /**
     * Get the truncationStrategy property: The truncation_strategy property.
     * 
     * @return the truncationStrategy value.
     */
    @Metadata(generated = true)
    public TruncationObject getTruncationStrategy() {
        return this.truncationStrategy;
    }

    /**
     * Set the truncationStrategy property: The truncation_strategy property.
     * 
     * @param truncationStrategy the truncationStrategy value to set.
     * @return the CreateRunRequest object itself.
     */
    @Metadata(generated = true)
    public CreateRunRequest setTruncationStrategy(TruncationObject truncationStrategy) {
        this.truncationStrategy = truncationStrategy;
        return this;
    }

    /**
     * Get the toolChoice property: The tool_choice property.
     * 
     * @return the toolChoice value.
     */
    @Metadata(generated = true)
    public BinaryData getToolChoice() {
        return this.toolChoice;
    }

    /**
     * Set the toolChoice property: The tool_choice property.
     * 
     * @param toolChoice the toolChoice value to set.
     * @return the CreateRunRequest object itself.
     */
    @Metadata(generated = true)
    public CreateRunRequest setToolChoice(BinaryData toolChoice) {
        this.toolChoice = toolChoice;
        return this;
    }

    /**
     * Get the parallelToolCalls property: The parallel_tool_calls property.
     * 
     * @return the parallelToolCalls value.
     */
    @Metadata(generated = true)
    public Boolean isParallelToolCalls() {
        return this.parallelToolCalls;
    }

    /**
     * Set the parallelToolCalls property: The parallel_tool_calls property.
     * 
     * @param parallelToolCalls the parallelToolCalls value to set.
     * @return the CreateRunRequest object itself.
     */
    @Metadata(generated = true)
    public CreateRunRequest setParallelToolCalls(Boolean parallelToolCalls) {
        this.parallelToolCalls = parallelToolCalls;
        return this;
    }

    /**
     * Get the responseFormat property: The response_format property.
     * 
     * @return the responseFormat value.
     */
    @Metadata(generated = true)
    public BinaryData getResponseFormat() {
        return this.responseFormat;
    }

    /**
     * Set the responseFormat property: The response_format property.
     * 
     * @param responseFormat the responseFormat value to set.
     * @return the CreateRunRequest object itself.
     */
    @Metadata(generated = true)
    public CreateRunRequest setResponseFormat(BinaryData responseFormat) {
        this.responseFormat = responseFormat;
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Metadata(generated = true)
    @Override
    public JsonWriter toJson(JsonWriter jsonWriter) throws IOException {
        jsonWriter.writeStartObject();
        jsonWriter.writeStringField("assistant_id", this.assistantId);
        jsonWriter.writeStringField("model", this.model == null ? null : this.model.toString());
        jsonWriter.writeStringField("instructions", this.instructions);
        jsonWriter.writeStringField("additional_instructions", this.additionalInstructions);
        jsonWriter.writeArrayField("additional_messages", this.additionalMessages,
            (writer, element) -> writer.writeJson(element));
        jsonWriter.writeArrayField("tools", this.tools, (writer, element) -> writer.writeJson(element));
        jsonWriter.writeMapField("metadata", this.metadata, (writer, element) -> writer.writeString(element));
        jsonWriter.writeNumberField("temperature", this.temperature);
        jsonWriter.writeNumberField("top_p", this.topP);
        jsonWriter.writeBooleanField("stream", this.stream);
        jsonWriter.writeNumberField("max_prompt_tokens", this.maxPromptTokens);
        jsonWriter.writeNumberField("max_completion_tokens", this.maxCompletionTokens);
        jsonWriter.writeJsonField("truncation_strategy", this.truncationStrategy);
        if (this.toolChoice != null) {
            jsonWriter.writeUntypedField("tool_choice", this.toolChoice.toObject(Object.class));
        }
        jsonWriter.writeBooleanField("parallel_tool_calls", this.parallelToolCalls);
        if (this.responseFormat != null) {
            jsonWriter.writeUntypedField("response_format", this.responseFormat.toObject(Object.class));
        }
        return jsonWriter.writeEndObject();
    }

    /**
     * Reads an instance of CreateRunRequest from the JsonReader.
     * 
     * @param jsonReader The JsonReader being read.
     * @return An instance of CreateRunRequest if the JsonReader was pointing to an instance of it, or null if it was
     * pointing to JSON null.
     * @throws IllegalStateException If the deserialized JSON object was missing any required properties.
     * @throws IOException If an error occurs while reading the CreateRunRequest.
     */
    @Metadata(generated = true)
    public static CreateRunRequest fromJson(JsonReader jsonReader) throws IOException {
        return jsonReader.readObject(reader -> {
            String assistantId = null;
            CreateRunRequestModel model = null;
            String instructions = null;
            String additionalInstructions = null;
            List<CreateMessageRequest> additionalMessages = null;
            List<AssistantToolDefinition> tools = null;
            Map<String, String> metadata = null;
            Double temperature = null;
            Double topP = null;
            Boolean stream = null;
            Integer maxPromptTokens = null;
            Integer maxCompletionTokens = null;
            TruncationObject truncationStrategy = null;
            BinaryData toolChoice = null;
            Boolean parallelToolCalls = null;
            BinaryData responseFormat = null;
            while (reader.nextToken() != JsonToken.END_OBJECT) {
                String fieldName = reader.getFieldName();
                reader.nextToken();

                if ("assistant_id".equals(fieldName)) {
                    assistantId = reader.getString();
                } else if ("model".equals(fieldName)) {
                    model = CreateRunRequestModel.fromString(reader.getString());
                } else if ("instructions".equals(fieldName)) {
                    instructions = reader.getString();
                } else if ("additional_instructions".equals(fieldName)) {
                    additionalInstructions = reader.getString();
                } else if ("additional_messages".equals(fieldName)) {
                    additionalMessages = reader.readArray(reader1 -> CreateMessageRequest.fromJson(reader1));
                } else if ("tools".equals(fieldName)) {
                    tools = reader.readArray(reader1 -> AssistantToolDefinition.fromJson(reader1));
                } else if ("metadata".equals(fieldName)) {
                    metadata = reader.readMap(reader1 -> reader1.getString());
                } else if ("temperature".equals(fieldName)) {
                    temperature = reader.getNullable(JsonReader::getDouble);
                } else if ("top_p".equals(fieldName)) {
                    topP = reader.getNullable(JsonReader::getDouble);
                } else if ("stream".equals(fieldName)) {
                    stream = reader.getNullable(JsonReader::getBoolean);
                } else if ("max_prompt_tokens".equals(fieldName)) {
                    maxPromptTokens = reader.getNullable(JsonReader::getInt);
                } else if ("max_completion_tokens".equals(fieldName)) {
                    maxCompletionTokens = reader.getNullable(JsonReader::getInt);
                } else if ("truncation_strategy".equals(fieldName)) {
                    truncationStrategy = TruncationObject.fromJson(reader);
                } else if ("tool_choice".equals(fieldName)) {
                    toolChoice
                        = reader.getNullable(nonNullReader -> BinaryData.fromObject(nonNullReader.readUntyped()));
                } else if ("parallel_tool_calls".equals(fieldName)) {
                    parallelToolCalls = reader.getNullable(JsonReader::getBoolean);
                } else if ("response_format".equals(fieldName)) {
                    responseFormat
                        = reader.getNullable(nonNullReader -> BinaryData.fromObject(nonNullReader.readUntyped()));
                } else {
                    reader.skipChildren();
                }
            }
            CreateRunRequest deserializedCreateRunRequest = new CreateRunRequest(assistantId);
            deserializedCreateRunRequest.model = model;
            deserializedCreateRunRequest.instructions = instructions;
            deserializedCreateRunRequest.additionalInstructions = additionalInstructions;
            deserializedCreateRunRequest.additionalMessages = additionalMessages;
            deserializedCreateRunRequest.tools = tools;
            deserializedCreateRunRequest.metadata = metadata;
            deserializedCreateRunRequest.temperature = temperature;
            deserializedCreateRunRequest.topP = topP;
            deserializedCreateRunRequest.stream = stream;
            deserializedCreateRunRequest.maxPromptTokens = maxPromptTokens;
            deserializedCreateRunRequest.maxCompletionTokens = maxCompletionTokens;
            deserializedCreateRunRequest.truncationStrategy = truncationStrategy;
            deserializedCreateRunRequest.toolChoice = toolChoice;
            deserializedCreateRunRequest.parallelToolCalls = parallelToolCalls;
            deserializedCreateRunRequest.responseFormat = responseFormat;

            return deserializedCreateRunRequest;
        });
    }
}
